{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "469a3649-ede7-49dd-beee-262bd31ea93a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: unknown command \"isstall\" - maybe you meant \"install\"\r\n"
     ]
    }
   ],
   "source": [
    "!pip isstall tensorflow\n",
    "import tensorflow as tf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d8bd422-d09a-4ee0-9f45-197c57df2645",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'2.6.2'"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "114269c9-be35-4163-bf08-a54af0674c9f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imageio in /opt/conda/lib/python3.9/site-packages (2.14.1)\r\n",
      "Requirement already satisfied: pillow>=8.3.2 in /opt/conda/lib/python3.9/site-packages (from imageio) (8.4.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from imageio) (1.19.5)\r\n",
      "Collecting git+https://github.com/tensorflow/docs\r\n",
      "  Cloning https://github.com/tensorflow/docs to /tmp/pip-req-build-yh8jjgvd\r\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/tensorflow/docs /tmp/pip-req-build-yh8jjgvd\r\n",
      "  Resolved https://github.com/tensorflow/docs to commit 5d42b865e45d76d738418b838c62659b7f88d1bd\r\n",
      "  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hCollecting astor\r\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\r\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.9/site-packages (from tensorflow-docs==0.0.0.dev0) (0.15.0)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from tensorflow-docs==0.0.0.dev0) (3.0.3)\r\n",
      "Requirement already satisfied: protobuf<3.20,>=3.12.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow-docs==0.0.0.dev0) (3.19.3)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.9/site-packages (from tensorflow-docs==0.0.0.dev0) (6.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from absl-py->tensorflow-docs==0.0.0.dev0) (1.15.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from jinja2->tensorflow-docs==0.0.0.dev0) (2.0.1)\r\n",
      "Building wheels for collected packages: tensorflow-docs\r\n",
      "  Building wheel for tensorflow-docs (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for tensorflow-docs: filename=tensorflow_docs-0.0.0.dev0-py3-none-any.whl size=176109 sha256=5474b8aabd1f34c94311fa1ce1fdfad54c720f2dd9a552347fb0315849a6d720\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-xpies8lt/wheels/fc/f8/3b/5d21409a59cb1be9b1ade11f682039ced75b84de9dd6a0c8de\r\n",
      "Successfully built tensorflow-docs\r\n",
      "Installing collected packages: astor, tensorflow-docs\r\n",
      "Successfully installed astor-0.8.1 tensorflow-docs-0.0.0.dev0\r\n"
     ]
    }
   ],
   "source": [
    "# To generate GIFs\n",
    "!pip install imageio\n",
    "!pip install git+https://github.com/tensorflow/docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba30d264-26d1-4002-9fb3-05c81deaf365",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5bed6e8-3895-4c2a-9851-0752c3ebf9d8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n",
      "11501568/11490434 [==============================] - 1s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "60000"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()\n",
    "len(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75c49e59-453c-48d3-9800-ff658b6773d9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 (60000, 28, 28, 1) float32\n"
     ]
    }
   ],
   "source": [
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "train_images = (train_images - 127.5) / 127.5  # Normalize the images to [-1, 1]\n",
    "print(len(train_images),train_images.shape,train_images.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f941c0ed-a161-45ff-98cf-2e0b31194ed6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = int(256*(2/1))\n",
    "\n",
    "EPOCHS = 1000\n",
    "noise_dim = 8\n",
    "num_examples_to_generate = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42eb3329-0edf-4192-846a-e154e18bf748",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-26 21:38:31.934390: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-06-26 21:38:31.943404: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-06-26 21:38:31.943700: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-06-26 21:38:31.944936: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-26 21:38:31.946973: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-06-26 21:38:31.947382: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-06-26 21:38:31.947635: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-06-26 21:38:32.885066: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-06-26 21:38:32.885345: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-06-26 21:38:32.885363: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1594] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2022-06-26 21:38:32.885585: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-06-26 21:38:32.885638: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6800 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:2d:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# Batch and shuffle the data\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1fe49b4-fe19-4db3-a61d-6d23dacf68fd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "for image_batch in train_dataset:\n",
    "    print(image_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29452f40-0aa7-474f-b8f0-8f9a7f717db0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9a7346f-d08c-4a19-b4e6-282cf5987dfc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(7*7*512, use_bias=False, input_shape=(noise_dim,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Reshape((7, 7, 512)))\n",
    "    assert model.output_shape == (None, 7, 7, 512)  # Note: None is the batch size\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(512, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 7, 7, 512)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(256, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 14, 14, 256)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 14, 14, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, 28, 28, 64)\n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh',name=\"upscale\"))\n",
    "    assert model.output_shape == (None, 56, 56, 1)\n",
    "    \n",
    "    model.add(layers.Resizing (28,28,interpolation='bicubic', name =\"out\"))\n",
    "    assert model.output_shape == (None, 28, 28, 1)\n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078004ac-2567-4157-9fe1-7fa4912d7d82",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2495ee3c-3107-4b9a-b69b-aa4b801df5e5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-15 20:50:58.481354: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-06-15 20:51:00.050558: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8101\n",
      "2022-06-15 20:51:03.012300: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-06-15 20:51:03.012913: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-06-15 20:51:03.012990: W tensorflow/stream_executor/gpu/asm_compiler.cc:77] Couldn't get ptxas version string: Internal: Couldn't invoke ptxas --version\n",
      "2022-06-15 20:51:03.013570: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-06-15 20:51:03.013633: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 25088)             200704    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 25088)             100352    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 7, 7, 512)         6553600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 14, 14, 256)       3276800   \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 14, 14, 128)       819200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 28, 28, 64)        204800    \n",
      "_________________________________________________________________\n",
      "upscale (Conv2DTranspose)    (None, 56, 56, 1)         1600      \n",
      "_________________________________________________________________\n",
      "out (Resizing)               (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 11,160,640\n",
      "Trainable params: 11,108,672\n",
      "Non-trainable params: 51,968\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f91a0240820>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "generator = make_generator_model()\n",
    "\n",
    "upscale_model = Model(inputs=generator.input,outputs=generator.get_layer(\"upscale\").output)\n",
    "                      \n",
    "noise = tf.random.normal([1, noise_dim])\n",
    "generated_image = generator(noise, training=False)\n",
    "print (generator.summary())\n",
    "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d311030b-b393-43de-bb7a-8ac76021f2dc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same',\n",
    "                                     input_shape=[28, 28, 1]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.25))\n",
    "\n",
    "    model.add(layers.Conv2D(256, (5, 5), strides=(1,1 ), padding='same',\n",
    "                            input_shape=[14,14,128] ))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.25))\n",
    "\n",
    "    model.add(layers.Conv2D(512, (5, 5), strides=(2,2 ), padding='same',\n",
    "                            input_shape=[14,14,128] ))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.25))\n",
    "\n",
    "    model.add(layers.Flatten())    \n",
    "    model.add(layers.Dense(64))\n",
    "    model.add(layers.Dense(64))\n",
    "    model.add(layers.Dense(64))\n",
    "    model.add(layers.Dense(32))    \n",
    "    model.add(layers.Dense(16))    \n",
    "    model.add(layers.Dense(8))        \n",
    "    model.add(layers.Dense(1))  \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bdde1642-a121-49a2-98e2-8321f9756569",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[-3.2477892e-06]], shape=(1, 1), dtype=float32)\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 14, 14, 128)       3328      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 256)       819456    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 512)         3277312   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                1605696   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 5,716,865\n",
      "Trainable params: 5,716,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "discriminator = make_discriminator_model()\n",
    "decision = discriminator(generated_image)\n",
    "print (decision)\n",
    "print(discriminator.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4713f551-5810-44ec-8d81-42b42d50da21",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# This method returns a helper function to compute cross entropy loss\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7feb4801-b488-4178-8769-264088290a08",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77db94c5-8151-4808-87c8-3eedd03382c9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98306723-ec35-4657-8f3a-642a21d54873",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb9e8413-22b7-4eac-ba52-73afaa6be3d2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0c65f0c-7f34-4d1a-ab8f-43bdb7662eb8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# You will reuse this seed overtime (so it's easier)\n",
    "# to visualize progress in the animated GIF)\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0eec18d1-c077-4815-ab45-3f0b71624691",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Notice the use of `tf.function`\n",
    "# This annotation causes the function to be \"compiled\".\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "      generated_images = generator(noise, training=True)\n",
    "\n",
    "      real_output = discriminator(images, training=True)\n",
    "      fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "      gen_loss = generator_loss(fake_output)\n",
    "      disc_loss = discriminator_loss(real_output, fake_output)\n",
    "    \n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "    return (disc_loss,gen_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45400f3f-83bd-45c2-9cf2-d3113f502466",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "  for epoch in range(epochs):\n",
    "    disc_loss_epoch_tot=0\n",
    "    gen_loss_epoch_tot=0\n",
    "    start = time.time()\n",
    "\n",
    "    for image_batch in dataset:\n",
    "      disc_loss,gen_loss=train_step(image_batch)\n",
    "      disc_loss_epoch_tot +=disc_loss\n",
    "      gen_loss_epoch_tot +=gen_loss\n",
    "\n",
    "    # Produce images for the GIF as you go\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator,\n",
    "                             epoch + 1,\n",
    "                             seed)\n",
    "    \n",
    "    print(disc_loss_epoch_tot/epochs,gen_loss_epoch_tot/epochs)\n",
    "    \n",
    "    # Save the model every 15 epochs\n",
    "    if (epoch + 1) % 15 == 0:\n",
    "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "  # Generate after the final epoch\n",
    "  display.clear_output(wait=True)\n",
    "  generate_and_save_images(generator,\n",
    "                           epochs,\n",
    "                           seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a6abe88-689e-40e4-9182-2bfa8e5b3b6b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "  # Notice `training` is set to False.\n",
    "  # This is so all layers run in inference mode (batchnorm).\n",
    "  predictions = model(test_input, training=False)\n",
    "  predictions = upscale_model(test_input,training=False)\n",
    "  fig = plt.figure(figsize=(16, 8))\n",
    "\n",
    "  for i in range(predictions.shape[0]):\n",
    "      plt.subplot(8, 2, i+1)\n",
    "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "      plt.axis('off')\n",
    "\n",
    "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250b5d23-2f1e-4749-b9df-8845e25b6c4f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train(train_dataset, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9e38ed-7a5c-49d0-9832-b9e6e682c37c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47953902-ab8b-4cfd-9cf1-049026d09a11",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc5c4f3-5824-4d1d-be7a-1c6825ffd586",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c9b73f-016f-4db1-9965-8fe05ca5bd3e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7d082f-e193-4122-9c34-8c4a408d1655",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155d41d7-1856-4dde-bb0f-7f9308a5150b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b61e43-e817-4a08-821a-a0a57b7e1210",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a4a215-4629-48d3-9254-c9f319efc093",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e4eafe-2b84-4fe7-8b6f-c4d04d15e0f6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdc5b06-aa2b-4044-aef2-c2c44fa1e763",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3441b96c-1b91-4b4f-8347-5dd98d1561cd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176e143a-4a9b-43a3-8592-504d25e20878",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccb5bfd-73e2-4e77-a8cd-e94256914d20",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0b98f7-3e2e-403f-a7e9-55b1d78103db",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af351524-5cbd-4803-a9cb-cec2148b0832",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a36db89-7f7b-48be-bb37-9fa7b21f46f0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import imageio\n",
    "anim_file = 'dcgan5.1000.gif'\n",
    "\n",
    "with imageio.get_writer(anim_file, mode='I') as writer:\n",
    "  filenames = glob.glob('image*.png')\n",
    "  filenames = sorted(filenames)\n",
    "  for filename in filenames:\n",
    "    image = imageio.imread(filename)\n",
    "    writer.append_data(image)\n",
    "  image = imageio.imread(filename)\n",
    "  writer.append_data(image)\n",
    "\n",
    "import tensorflow_docs.vis.embed as embed\n",
    "embed.embed_file(anim_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3cb8f8-a4f0-4428-9c22-7f171db4f574",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce54652-5c5c-4585-8d42-48a2d7c3b4d0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4b0c0f-f5fe-45bb-a4c8-e08310f96b41",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}